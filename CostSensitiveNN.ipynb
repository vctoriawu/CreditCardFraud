{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt \n",
        "import io\n",
        "import keras.backend as K\n",
        "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.utils import class_weight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Import data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "# Store the input data in a dataframe\n",
        "fraud_data \u003d pd.read_csv(\"creditcard.csv\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "data": {
            "text/plain": "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n0       1.546846     0.873553 -1.798448 -0.830291  2.185209 -1.820608   \n1       2.400335    -0.058412  0.973212 -0.874979 -0.448158 -1.121518   \n2      -0.028645     0.875856  0.082126  0.655715 -2.612569 -1.396482   \n3      -0.064976    -0.157650  1.211461 -0.098931  0.371881  0.056012   \n4       0.237546    -0.865623  1.259835 -0.196615  0.467977  0.162764   \n\n         V5        V6        V7        V8  ...       V20       V21       V22  \\\n0 -0.854633  0.905317 -1.245491 -1.233351  ... -1.194357  0.891557 -1.315785   \n1 -0.847891 -1.471452  0.391356 -0.351814  ...  0.209336  0.058744 -0.062798   \n2  3.139501  2.977854  0.344041  0.937190  ... -0.215205 -0.127424 -0.341526   \n3 -0.714667 -0.940265 -0.145232 -0.057228  ... -0.106237  0.078102  0.144624   \n4 -0.575144 -0.386814 -0.518503 -0.076230  ... -0.097335 -0.123770 -0.212120   \n\n        V23       V24       V25       V26       V27       V28  Class  \n0 -0.237302  0.646676  0.134546  1.252547  0.345407 -0.046461      0  \n1 -0.320673  0.448400  0.713861  0.078804 -0.056332  0.032475      0  \n2  0.301080  0.608449 -0.746785  0.185163 -0.375947 -0.286098      0  \n3 -0.033397  0.600429  0.284776  1.042134 -0.097524 -0.006914      0  \n4 -0.122714 -0.475957  0.262548  1.085564 -0.104039 -0.001713      0  \n\n[5 rows x 31 columns]",
            "text/html": "\u003cdiv\u003e\n\u003cstyle scoped\u003e\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\u003c/style\u003e\n\u003ctable border\u003d\"1\" class\u003d\"dataframe\"\u003e\n  \u003cthead\u003e\n    \u003ctr style\u003d\"text-align: right;\"\u003e\n      \u003cth\u003e\u003c/th\u003e\n      \u003cth\u003escaled_amount\u003c/th\u003e\n      \u003cth\u003escaled_time\u003c/th\u003e\n      \u003cth\u003eV1\u003c/th\u003e\n      \u003cth\u003eV2\u003c/th\u003e\n      \u003cth\u003eV3\u003c/th\u003e\n      \u003cth\u003eV4\u003c/th\u003e\n      \u003cth\u003eV5\u003c/th\u003e\n      \u003cth\u003eV6\u003c/th\u003e\n      \u003cth\u003eV7\u003c/th\u003e\n      \u003cth\u003eV8\u003c/th\u003e\n      \u003cth\u003e...\u003c/th\u003e\n      \u003cth\u003eV20\u003c/th\u003e\n      \u003cth\u003eV21\u003c/th\u003e\n      \u003cth\u003eV22\u003c/th\u003e\n      \u003cth\u003eV23\u003c/th\u003e\n      \u003cth\u003eV24\u003c/th\u003e\n      \u003cth\u003eV25\u003c/th\u003e\n      \u003cth\u003eV26\u003c/th\u003e\n      \u003cth\u003eV27\u003c/th\u003e\n      \u003cth\u003eV28\u003c/th\u003e\n      \u003cth\u003eClass\u003c/th\u003e\n    \u003c/tr\u003e\n  \u003c/thead\u003e\n  \u003ctbody\u003e\n    \u003ctr\u003e\n      \u003cth\u003e0\u003c/th\u003e\n      \u003ctd\u003e1.546846\u003c/td\u003e\n      \u003ctd\u003e0.873553\u003c/td\u003e\n      \u003ctd\u003e-1.798448\u003c/td\u003e\n      \u003ctd\u003e-0.830291\u003c/td\u003e\n      \u003ctd\u003e2.185209\u003c/td\u003e\n      \u003ctd\u003e-1.820608\u003c/td\u003e\n      \u003ctd\u003e-0.854633\u003c/td\u003e\n      \u003ctd\u003e0.905317\u003c/td\u003e\n      \u003ctd\u003e-1.245491\u003c/td\u003e\n      \u003ctd\u003e-1.233351\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e-1.194357\u003c/td\u003e\n      \u003ctd\u003e0.891557\u003c/td\u003e\n      \u003ctd\u003e-1.315785\u003c/td\u003e\n      \u003ctd\u003e-0.237302\u003c/td\u003e\n      \u003ctd\u003e0.646676\u003c/td\u003e\n      \u003ctd\u003e0.134546\u003c/td\u003e\n      \u003ctd\u003e1.252547\u003c/td\u003e\n      \u003ctd\u003e0.345407\u003c/td\u003e\n      \u003ctd\u003e-0.046461\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e1\u003c/th\u003e\n      \u003ctd\u003e2.400335\u003c/td\u003e\n      \u003ctd\u003e-0.058412\u003c/td\u003e\n      \u003ctd\u003e0.973212\u003c/td\u003e\n      \u003ctd\u003e-0.874979\u003c/td\u003e\n      \u003ctd\u003e-0.448158\u003c/td\u003e\n      \u003ctd\u003e-1.121518\u003c/td\u003e\n      \u003ctd\u003e-0.847891\u003c/td\u003e\n      \u003ctd\u003e-1.471452\u003c/td\u003e\n      \u003ctd\u003e0.391356\u003c/td\u003e\n      \u003ctd\u003e-0.351814\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e0.209336\u003c/td\u003e\n      \u003ctd\u003e0.058744\u003c/td\u003e\n      \u003ctd\u003e-0.062798\u003c/td\u003e\n      \u003ctd\u003e-0.320673\u003c/td\u003e\n      \u003ctd\u003e0.448400\u003c/td\u003e\n      \u003ctd\u003e0.713861\u003c/td\u003e\n      \u003ctd\u003e0.078804\u003c/td\u003e\n      \u003ctd\u003e-0.056332\u003c/td\u003e\n      \u003ctd\u003e0.032475\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e2\u003c/th\u003e\n      \u003ctd\u003e-0.028645\u003c/td\u003e\n      \u003ctd\u003e0.875856\u003c/td\u003e\n      \u003ctd\u003e0.082126\u003c/td\u003e\n      \u003ctd\u003e0.655715\u003c/td\u003e\n      \u003ctd\u003e-2.612569\u003c/td\u003e\n      \u003ctd\u003e-1.396482\u003c/td\u003e\n      \u003ctd\u003e3.139501\u003c/td\u003e\n      \u003ctd\u003e2.977854\u003c/td\u003e\n      \u003ctd\u003e0.344041\u003c/td\u003e\n      \u003ctd\u003e0.937190\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e-0.215205\u003c/td\u003e\n      \u003ctd\u003e-0.127424\u003c/td\u003e\n      \u003ctd\u003e-0.341526\u003c/td\u003e\n      \u003ctd\u003e0.301080\u003c/td\u003e\n      \u003ctd\u003e0.608449\u003c/td\u003e\n      \u003ctd\u003e-0.746785\u003c/td\u003e\n      \u003ctd\u003e0.185163\u003c/td\u003e\n      \u003ctd\u003e-0.375947\u003c/td\u003e\n      \u003ctd\u003e-0.286098\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e3\u003c/th\u003e\n      \u003ctd\u003e-0.064976\u003c/td\u003e\n      \u003ctd\u003e-0.157650\u003c/td\u003e\n      \u003ctd\u003e1.211461\u003c/td\u003e\n      \u003ctd\u003e-0.098931\u003c/td\u003e\n      \u003ctd\u003e0.371881\u003c/td\u003e\n      \u003ctd\u003e0.056012\u003c/td\u003e\n      \u003ctd\u003e-0.714667\u003c/td\u003e\n      \u003ctd\u003e-0.940265\u003c/td\u003e\n      \u003ctd\u003e-0.145232\u003c/td\u003e\n      \u003ctd\u003e-0.057228\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e-0.106237\u003c/td\u003e\n      \u003ctd\u003e0.078102\u003c/td\u003e\n      \u003ctd\u003e0.144624\u003c/td\u003e\n      \u003ctd\u003e-0.033397\u003c/td\u003e\n      \u003ctd\u003e0.600429\u003c/td\u003e\n      \u003ctd\u003e0.284776\u003c/td\u003e\n      \u003ctd\u003e1.042134\u003c/td\u003e\n      \u003ctd\u003e-0.097524\u003c/td\u003e\n      \u003ctd\u003e-0.006914\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n    \u003ctr\u003e\n      \u003cth\u003e4\u003c/th\u003e\n      \u003ctd\u003e0.237546\u003c/td\u003e\n      \u003ctd\u003e-0.865623\u003c/td\u003e\n      \u003ctd\u003e1.259835\u003c/td\u003e\n      \u003ctd\u003e-0.196615\u003c/td\u003e\n      \u003ctd\u003e0.467977\u003c/td\u003e\n      \u003ctd\u003e0.162764\u003c/td\u003e\n      \u003ctd\u003e-0.575144\u003c/td\u003e\n      \u003ctd\u003e-0.386814\u003c/td\u003e\n      \u003ctd\u003e-0.518503\u003c/td\u003e\n      \u003ctd\u003e-0.076230\u003c/td\u003e\n      \u003ctd\u003e...\u003c/td\u003e\n      \u003ctd\u003e-0.097335\u003c/td\u003e\n      \u003ctd\u003e-0.123770\u003c/td\u003e\n      \u003ctd\u003e-0.212120\u003c/td\u003e\n      \u003ctd\u003e-0.122714\u003c/td\u003e\n      \u003ctd\u003e-0.475957\u003c/td\u003e\n      \u003ctd\u003e0.262548\u003c/td\u003e\n      \u003ctd\u003e1.085564\u003c/td\u003e\n      \u003ctd\u003e-0.104039\u003c/td\u003e\n      \u003ctd\u003e-0.001713\u003c/td\u003e\n      \u003ctd\u003e0\u003c/td\u003e\n    \u003c/tr\u003e\n  \u003c/tbody\u003e\n\u003c/table\u003e\n\u003cp\u003e5 rows Ã— 31 columns\u003c/p\u003e\n\u003c/div\u003e"
          },
          "metadata": {},
          "output_type": "execute_result",
          "execution_count": 4
        }
      ],
      "source": [
        "# shuffle the dataframe so that the inputs are in a random order\n",
        "df \u003d fraud_data.sample(frac\u003d1).reset_index(drop\u003dTrue)\n",
        "#\n",
        "# Scale the time -1 and 1, since the rest of the features are scaled\n",
        "robust_scaler \u003d RobustScaler()\n",
        "scaled_amount \u003d robust_scaler.fit_transform(df[\u0027Amount\u0027].values.reshape(-1,1))\n",
        "scaled_time \u003d robust_scaler.fit_transform(df[\u0027Time\u0027].values.reshape(-1,1))\n",
        "df.drop([\u0027Time\u0027,\u0027Amount\u0027], axis\u003d1, inplace\u003dTrue)\n",
        "\n",
        "# Insert into beginning of df\n",
        "df.insert(0, \u0027scaled_amount\u0027, scaled_amount)\n",
        "df.insert(1, \u0027scaled_time\u0027, scaled_time)\n",
        "\n",
        "# Show the result\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(227845, 30)\n(56962, 30)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": [
        "# Split the data into training (80%) and testing (20%)\n",
        "train, test \u003d train_test_split(df, test_size\u003d0.2)\n",
        "\n",
        "# Split data into features and labels\n",
        "train_features \u003d np.array(train.values[:,:30])\n",
        "train_labels \u003d np.array(train.values[:,-1])\n",
        "test_features \u003d np.array(test.values[:,:30])\n",
        "test_labels \u003d np.array(test.values[:,-1])\n",
        "\n",
        "print(train_features.shape)\n",
        "print(test_features.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": [
        "# Set how much we care about each mis-classification data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "# Set How much we value each mis-classification\nclass_weights \u003d class_weight.compute_class_weight(\"balanced\", np.unique(train_labels), train_labels)\nclass_weights[1] *\u003d2\n        "
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Create the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": "model \u003d Sequential()\n\nmodel.add(Dense(units\u003d50, kernel_initializer\u003d\u0027uniform\u0027, input_dim\u003dtrain_features.shape[1], activation\u003d\u0027relu\u0027))\nmodel.add(Dropout(.2))\nmodel.add(Dense(units\u003d25, kernel_initializer\u003d\u0027uniform\u0027, activation\u003d\u0027relu\u0027))\nmodel.add(Dropout(.2))\nmodel.add(Dense(15, kernel_initializer\u003d\u0027uniform\u0027, activation\u003d\u0027relu\u0027))\nmodel.add(Dense(1, kernel_initializer\u003d\u0027uniform\u0027, activation\u003d\u0027sigmoid\u0027))\n\n# Including the custom loss fxn\nmodel.compile(optimizer\u003d\u0027adam\u0027, metrics\u003d[\u0027accuracy\u0027], loss\u003d\"binary_crossentropy\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "metadata": false,
          "name": "#%%\n"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 31us/step - loss: 0.0923 - accuracy: 0.9981\n",
            "Epoch 2/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0190 - accuracy: 0.9989\n",
            "Epoch 3/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0179 - accuracy: 0.9992\n",
            "Epoch 4/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 29us/step - loss: 0.0170 - accuracy: 0.9993\n",
            "Epoch 5/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 29us/step - loss: 0.0163 - accuracy: 0.9993\n",
            "Epoch 6/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 29us/step - loss: 0.0159 - accuracy: 0.9993\n",
            "Epoch 7/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0152 - accuracy: 0.9993\n",
            "Epoch 8/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0147 - accuracy: 0.9993\n",
            "Epoch 9/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0151 - accuracy: 0.9993\n",
            "Epoch 10/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0140 - accuracy: 0.9993\n",
            "Epoch 11/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0144 - accuracy: 0.9994\n",
            "Epoch 12/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0138 - accuracy: 0.9994\n",
            "Epoch 13/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 29us/step - loss: 0.0140 - accuracy: 0.9994\n",
            "Epoch 14/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0139 - accuracy: 0.9994\n",
            "Epoch 15/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0131 - accuracy: 0.9994\n",
            "Epoch 16/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 31us/step - loss: 0.0130 - accuracy: 0.9994\n",
            "Epoch 17/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0137 - accuracy: 0.9994\n",
            "Epoch 18/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0130 - accuracy: 0.9994\n",
            "Epoch 19/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0129 - accuracy: 0.9994\n",
            "Epoch 20/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0130 - accuracy: 0.9994\n",
            "Epoch 21/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0130 - accuracy: 0.9994\n",
            "Epoch 22/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0125 - accuracy: 0.9994\n",
            "Epoch 23/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0125 - accuracy: 0.9994\n",
            "Epoch 24/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 30us/step - loss: 0.0122 - accuracy: 0.9995\n",
            "Epoch 25/25\n",
            "227845/227845 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 7s 31us/step - loss: 0.0124 - accuracy: 0.9995\n",
            "56962/56962 [\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d\u003d] - 1s 15us/step\n",
            "\n",
            "\n",
            "accuracy\u003d 0.9994557499885559\n",
            "Predicted      0   1\n",
            "Actual              \n",
            "0.0        56869   9\n",
            "1.0           22  62\n",
            "True Negative: 0.9983673326077034\n",
            "True Positive: 0.7380952380952381\n",
            "False Negative: 0.0003862223938766195\n",
            "False Positive: 0.10714285714285714\n"
          ]
        }
      ],
      "source": "model.fit(train_features, train_labels, batch_size\u003d50, epochs\u003d25, verbose\u003d1, class_weight\u003dclass_weights)\n\n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "\n# Get model accuracy \nscores \u003d model.evaluate(test_features, test_labels)\nprint(\u0027\\n\u0027)\nprint(\u0027accuracy\u003d\u0027,scores[1])\n\n# Get predictions from model\noutput \u003d model.predict_classes(test_features)\n\n# Show confusion matrix\ny_actu \u003d pd.Series(test_labels, name\u003d\u0027Actual\u0027)\ny_pred \u003d pd.Series(np.ndarray.flatten(output), name\u003d\u0027Predicted\u0027)\ndf_confusion \u003d pd.crosstab(y_actu, y_pred)\nprint(df_confusion)\n\n\nTN \u003d df_confusion[0][0]\nTP \u003d df_confusion[1][1]\nFN \u003d df_confusion[0][1]\nFP \u003d df_confusion[1][0]\n\n\nnum_positives \u003d  (np.count_nonzero(y_actu))\nnum_negatives \u003d y_actu.size - num_positives\nprint(\"Num Fraud: {}\".format(num_positives))\nprint(\"True Negative: {}\".format(TN/num_negatives))\nprint(\"True Positive: {}\".format(TP/num_positives))\nprint(\"False Negative: {}\".format(FN/(TP + FN)))\nprint(\"False Positive: {}\".format(FP/(FP + TN)))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "stem_cell": {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      },
      "source": ""
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}