{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "452NeuralNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpftVxps2kTi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt \n",
        "import io\n",
        "\t\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7d9y_tX3-nl",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "75438df4-b67f-49b5-b57a-ead99749f366"
      },
      "source": [
        "# Upload the data file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-71de1800-49c2-4a72-b5d8-38093e4ae700\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-71de1800-49c2-4a72-b5d8-38093e4ae700\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving creditcard.csv to creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0aml3VQ4aig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the input data in a dataframe\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['creditcard.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjN34PkU46AF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "4e157192-cc00-4cd6-b9ab-9c7d83b7dd77"
      },
      "source": [
        "# Show the first few inputs\n",
        "df2.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG-Et8wf9O8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to graph training history\n",
        "def show_train_history(train_history,train,validation):\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(train)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0IMrGXC9T1O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "7b10685a-b977-4589-e4ae-5ddb9ab057dc"
      },
      "source": [
        "# shuffle the dataframe so that the inputs are in a random order\n",
        "df = df2.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>69764.0</td>\n",
              "      <td>-0.526988</td>\n",
              "      <td>-0.375722</td>\n",
              "      <td>1.225768</td>\n",
              "      <td>-1.542791</td>\n",
              "      <td>-1.396605</td>\n",
              "      <td>0.328133</td>\n",
              "      <td>-0.921182</td>\n",
              "      <td>0.633863</td>\n",
              "      <td>-2.840685</td>\n",
              "      <td>1.093965</td>\n",
              "      <td>0.906701</td>\n",
              "      <td>-0.540281</td>\n",
              "      <td>0.292847</td>\n",
              "      <td>0.185672</td>\n",
              "      <td>0.628995</td>\n",
              "      <td>-0.531802</td>\n",
              "      <td>0.881680</td>\n",
              "      <td>0.470826</td>\n",
              "      <td>0.920989</td>\n",
              "      <td>-0.119742</td>\n",
              "      <td>-0.113528</td>\n",
              "      <td>-0.238980</td>\n",
              "      <td>0.266296</td>\n",
              "      <td>-0.361198</td>\n",
              "      <td>-0.703172</td>\n",
              "      <td>-0.305666</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.063379</td>\n",
              "      <td>72.65</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>137922.0</td>\n",
              "      <td>-1.484487</td>\n",
              "      <td>1.691573</td>\n",
              "      <td>-0.485658</td>\n",
              "      <td>-1.777540</td>\n",
              "      <td>-0.193241</td>\n",
              "      <td>0.599082</td>\n",
              "      <td>-1.789325</td>\n",
              "      <td>-5.355493</td>\n",
              "      <td>0.943862</td>\n",
              "      <td>-1.430727</td>\n",
              "      <td>0.862770</td>\n",
              "      <td>0.297554</td>\n",
              "      <td>-1.043041</td>\n",
              "      <td>-2.107229</td>\n",
              "      <td>-0.754725</td>\n",
              "      <td>2.033059</td>\n",
              "      <td>0.949395</td>\n",
              "      <td>1.521524</td>\n",
              "      <td>-1.711405</td>\n",
              "      <td>-1.349891</td>\n",
              "      <td>5.410068</td>\n",
              "      <td>-1.617483</td>\n",
              "      <td>0.187457</td>\n",
              "      <td>-0.669886</td>\n",
              "      <td>0.947539</td>\n",
              "      <td>1.349113</td>\n",
              "      <td>0.294830</td>\n",
              "      <td>0.266055</td>\n",
              "      <td>34.97</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>147910.0</td>\n",
              "      <td>2.117840</td>\n",
              "      <td>0.032706</td>\n",
              "      <td>-1.349937</td>\n",
              "      <td>0.225691</td>\n",
              "      <td>0.347023</td>\n",
              "      <td>-0.750889</td>\n",
              "      <td>0.261579</td>\n",
              "      <td>-0.365351</td>\n",
              "      <td>0.383390</td>\n",
              "      <td>0.034083</td>\n",
              "      <td>-1.177477</td>\n",
              "      <td>0.927233</td>\n",
              "      <td>1.581060</td>\n",
              "      <td>-0.045596</td>\n",
              "      <td>-0.057110</td>\n",
              "      <td>0.049023</td>\n",
              "      <td>-0.640651</td>\n",
              "      <td>-0.794426</td>\n",
              "      <td>0.420465</td>\n",
              "      <td>-0.112914</td>\n",
              "      <td>-0.323270</td>\n",
              "      <td>-0.723692</td>\n",
              "      <td>0.231334</td>\n",
              "      <td>-0.677907</td>\n",
              "      <td>-0.150849</td>\n",
              "      <td>0.238013</td>\n",
              "      <td>-0.062510</td>\n",
              "      <td>-0.064728</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35052.0</td>\n",
              "      <td>-7.561838</td>\n",
              "      <td>-8.762260</td>\n",
              "      <td>3.262736</td>\n",
              "      <td>4.459899</td>\n",
              "      <td>7.907726</td>\n",
              "      <td>-5.277949</td>\n",
              "      <td>-7.300743</td>\n",
              "      <td>0.608615</td>\n",
              "      <td>2.054200</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>-1.356754</td>\n",
              "      <td>0.895044</td>\n",
              "      <td>-0.340378</td>\n",
              "      <td>-0.778183</td>\n",
              "      <td>-0.173509</td>\n",
              "      <td>-1.273167</td>\n",
              "      <td>1.136090</td>\n",
              "      <td>-0.206200</td>\n",
              "      <td>2.681894</td>\n",
              "      <td>-1.369487</td>\n",
              "      <td>-0.602791</td>\n",
              "      <td>-0.354823</td>\n",
              "      <td>-1.682371</td>\n",
              "      <td>0.702022</td>\n",
              "      <td>-0.034471</td>\n",
              "      <td>0.037833</td>\n",
              "      <td>1.416846</td>\n",
              "      <td>-0.417153</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>136781.0</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>0.921101</td>\n",
              "      <td>0.024443</td>\n",
              "      <td>-0.756762</td>\n",
              "      <td>0.834505</td>\n",
              "      <td>-0.703046</td>\n",
              "      <td>1.074106</td>\n",
              "      <td>-0.224095</td>\n",
              "      <td>-0.158401</td>\n",
              "      <td>-0.442254</td>\n",
              "      <td>-1.363561</td>\n",
              "      <td>0.474411</td>\n",
              "      <td>1.194148</td>\n",
              "      <td>-0.140489</td>\n",
              "      <td>-0.469268</td>\n",
              "      <td>0.058708</td>\n",
              "      <td>-0.720641</td>\n",
              "      <td>-0.652832</td>\n",
              "      <td>0.169044</td>\n",
              "      <td>0.054725</td>\n",
              "      <td>-0.292949</td>\n",
              "      <td>-0.611702</td>\n",
              "      <td>-0.025337</td>\n",
              "      <td>-0.632709</td>\n",
              "      <td>-0.360520</td>\n",
              "      <td>0.177541</td>\n",
              "      <td>0.252746</td>\n",
              "      <td>0.092793</td>\n",
              "      <td>4.49</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   69764.0 -0.526988 -0.375722  1.225768  ...  0.056124  0.063379   72.65      0\n",
              "1  137922.0 -1.484487  1.691573 -0.485658  ...  0.294830  0.266055   34.97      0\n",
              "2  147910.0  2.117840  0.032706 -1.349937  ... -0.062510 -0.064728    0.99      0\n",
              "3   35052.0 -7.561838 -8.762260  3.262736  ...  1.416846 -0.417153    1.00      0\n",
              "4  136781.0  0.091292  0.921101  0.024443  ...  0.252746  0.092793    4.49      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDgDvoYHGncH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the time and amount columns to be between -1 and 1, since the rest of the features are scaled\n",
        "robust_scaler = RobustScaler()\n",
        "\n",
        "df['scaled_amount'] = robust_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['scaled_time'] = robust_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "df.drop(['Time','Amount'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSwOsQCG0si",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "d0170221-98dd-44ff-deb6-8717f4aa4d18"
      },
      "source": [
        "# Scaled amount and time\n",
        "scaled_amount = df['scaled_amount']\n",
        "scaled_time = df['scaled_time']\n",
        "\n",
        "# Insert into beginning of df\n",
        "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
        "df.insert(0, 'scaled_amount', scaled_amount)\n",
        "df.insert(1, 'scaled_time', scaled_time)\n",
        "\n",
        "# Show the result\n",
        "df.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.707748</td>\n",
              "      <td>-0.175378</td>\n",
              "      <td>-0.526988</td>\n",
              "      <td>-0.375722</td>\n",
              "      <td>1.225768</td>\n",
              "      <td>-1.542791</td>\n",
              "      <td>-1.396605</td>\n",
              "      <td>0.328133</td>\n",
              "      <td>-0.921182</td>\n",
              "      <td>0.633863</td>\n",
              "      <td>-2.840685</td>\n",
              "      <td>1.093965</td>\n",
              "      <td>0.906701</td>\n",
              "      <td>-0.540281</td>\n",
              "      <td>0.292847</td>\n",
              "      <td>0.185672</td>\n",
              "      <td>0.628995</td>\n",
              "      <td>-0.531802</td>\n",
              "      <td>0.881680</td>\n",
              "      <td>0.470826</td>\n",
              "      <td>0.920989</td>\n",
              "      <td>-0.119742</td>\n",
              "      <td>-0.113528</td>\n",
              "      <td>-0.238980</td>\n",
              "      <td>0.266296</td>\n",
              "      <td>-0.361198</td>\n",
              "      <td>-0.703172</td>\n",
              "      <td>-0.305666</td>\n",
              "      <td>0.056124</td>\n",
              "      <td>0.063379</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.181234</td>\n",
              "      <td>0.625360</td>\n",
              "      <td>-1.484487</td>\n",
              "      <td>1.691573</td>\n",
              "      <td>-0.485658</td>\n",
              "      <td>-1.777540</td>\n",
              "      <td>-0.193241</td>\n",
              "      <td>0.599082</td>\n",
              "      <td>-1.789325</td>\n",
              "      <td>-5.355493</td>\n",
              "      <td>0.943862</td>\n",
              "      <td>-1.430727</td>\n",
              "      <td>0.862770</td>\n",
              "      <td>0.297554</td>\n",
              "      <td>-1.043041</td>\n",
              "      <td>-2.107229</td>\n",
              "      <td>-0.754725</td>\n",
              "      <td>2.033059</td>\n",
              "      <td>0.949395</td>\n",
              "      <td>1.521524</td>\n",
              "      <td>-1.711405</td>\n",
              "      <td>-1.349891</td>\n",
              "      <td>5.410068</td>\n",
              "      <td>-1.617483</td>\n",
              "      <td>0.187457</td>\n",
              "      <td>-0.669886</td>\n",
              "      <td>0.947539</td>\n",
              "      <td>1.349113</td>\n",
              "      <td>0.294830</td>\n",
              "      <td>0.266055</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.293579</td>\n",
              "      <td>0.742701</td>\n",
              "      <td>2.117840</td>\n",
              "      <td>0.032706</td>\n",
              "      <td>-1.349937</td>\n",
              "      <td>0.225691</td>\n",
              "      <td>0.347023</td>\n",
              "      <td>-0.750889</td>\n",
              "      <td>0.261579</td>\n",
              "      <td>-0.365351</td>\n",
              "      <td>0.383390</td>\n",
              "      <td>0.034083</td>\n",
              "      <td>-1.177477</td>\n",
              "      <td>0.927233</td>\n",
              "      <td>1.581060</td>\n",
              "      <td>-0.045596</td>\n",
              "      <td>-0.057110</td>\n",
              "      <td>0.049023</td>\n",
              "      <td>-0.640651</td>\n",
              "      <td>-0.794426</td>\n",
              "      <td>0.420465</td>\n",
              "      <td>-0.112914</td>\n",
              "      <td>-0.323270</td>\n",
              "      <td>-0.723692</td>\n",
              "      <td>0.231334</td>\n",
              "      <td>-0.677907</td>\n",
              "      <td>-0.150849</td>\n",
              "      <td>0.238013</td>\n",
              "      <td>-0.062510</td>\n",
              "      <td>-0.064728</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.293440</td>\n",
              "      <td>-0.583184</td>\n",
              "      <td>-7.561838</td>\n",
              "      <td>-8.762260</td>\n",
              "      <td>3.262736</td>\n",
              "      <td>4.459899</td>\n",
              "      <td>7.907726</td>\n",
              "      <td>-5.277949</td>\n",
              "      <td>-7.300743</td>\n",
              "      <td>0.608615</td>\n",
              "      <td>2.054200</td>\n",
              "      <td>0.982923</td>\n",
              "      <td>-1.356754</td>\n",
              "      <td>0.895044</td>\n",
              "      <td>-0.340378</td>\n",
              "      <td>-0.778183</td>\n",
              "      <td>-0.173509</td>\n",
              "      <td>-1.273167</td>\n",
              "      <td>1.136090</td>\n",
              "      <td>-0.206200</td>\n",
              "      <td>2.681894</td>\n",
              "      <td>-1.369487</td>\n",
              "      <td>-0.602791</td>\n",
              "      <td>-0.354823</td>\n",
              "      <td>-1.682371</td>\n",
              "      <td>0.702022</td>\n",
              "      <td>-0.034471</td>\n",
              "      <td>0.037833</td>\n",
              "      <td>1.416846</td>\n",
              "      <td>-0.417153</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.244673</td>\n",
              "      <td>0.611955</td>\n",
              "      <td>0.091292</td>\n",
              "      <td>0.921101</td>\n",
              "      <td>0.024443</td>\n",
              "      <td>-0.756762</td>\n",
              "      <td>0.834505</td>\n",
              "      <td>-0.703046</td>\n",
              "      <td>1.074106</td>\n",
              "      <td>-0.224095</td>\n",
              "      <td>-0.158401</td>\n",
              "      <td>-0.442254</td>\n",
              "      <td>-1.363561</td>\n",
              "      <td>0.474411</td>\n",
              "      <td>1.194148</td>\n",
              "      <td>-0.140489</td>\n",
              "      <td>-0.469268</td>\n",
              "      <td>0.058708</td>\n",
              "      <td>-0.720641</td>\n",
              "      <td>-0.652832</td>\n",
              "      <td>0.169044</td>\n",
              "      <td>0.054725</td>\n",
              "      <td>-0.292949</td>\n",
              "      <td>-0.611702</td>\n",
              "      <td>-0.025337</td>\n",
              "      <td>-0.632709</td>\n",
              "      <td>-0.360520</td>\n",
              "      <td>0.177541</td>\n",
              "      <td>0.252746</td>\n",
              "      <td>0.092793</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   scaled_amount  scaled_time        V1  ...       V27       V28  Class\n",
              "0       0.707748    -0.175378 -0.526988  ...  0.056124  0.063379      0\n",
              "1       0.181234     0.625360 -1.484487  ...  0.294830  0.266055      0\n",
              "2      -0.293579     0.742701  2.117840  ... -0.062510 -0.064728      0\n",
              "3      -0.293440    -0.583184 -7.561838  ...  1.416846 -0.417153      0\n",
              "4      -0.244673     0.611955  0.091292  ...  0.252746  0.092793      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-18ULZbKzL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into training (80%) and testing (20%)\n",
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VriS6xtJa8Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "c3e615ec-2d56-4653-a662-f41f92214cf8"
      },
      "source": [
        "# Upsample fraud data\n",
        "'''df_genuine = train[train.Class==0]\n",
        "df_fraud = train[train.Class==1]\n",
        "\n",
        "df_fraud_upsampled = resample(df_fraud, \n",
        "                                 replace=True,     \n",
        "                                 n_samples=len(df_genuine.index),    \n",
        "                                 random_state=123) \n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_genuine, df_fraud_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled.Class.value_counts()'''"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'df_genuine = train[train.Class==0]\\ndf_fraud = train[train.Class==1]\\n\\ndf_fraud_upsampled = resample(df_fraud, \\n                                 replace=True,     \\n                                 n_samples=len(df_genuine.index),    \\n                                 random_state=123) \\n\\n# Combine majority class with upsampled minority class\\ndf_upsampled = pd.concat([df_genuine, df_fraud_upsampled])\\n \\n# Display new class counts\\ndf_upsampled.Class.value_counts()'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVvj1GRw-0dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into features and labels\n",
        "train_features = np.array(train.values[:,0:30])\n",
        "train_labels = np.array(train.values[:,-1])\n",
        "test_features = np.array(test.values[:,0:30])\n",
        "test_labels = np.array(test.values[:,-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0v2zN9TMa0T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ddf5342-2029-4f16-b247-7bdce911d8d8"
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(227845, 30)\n",
            "(56962, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xywPxz4d_z57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "b93b2ea9-2572-408e-ac11-aff344953f94"
      },
      "source": [
        "# Neural network model - may play around with number of layers and nodes a bit more\n",
        "model = Sequential()\n",
        "model.add(Dense(units=200, \n",
        "                input_dim=30, \n",
        "                kernel_initializer='uniform', \n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=200,  \n",
        "                kernel_initializer='uniform', \n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1,\n",
        "                kernel_initializer='uniform',\n",
        "                activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 200)               6200      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               40200     \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 201       \n",
            "=================================================================\n",
            "Total params: 46,601\n",
            "Trainable params: 46,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x7FkA_lAPzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fe82d8a2-8652-4b7d-f05e-29f6f655563e"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "train_history = model.fit(x=train_features, y=train_labels,\n",
        "                          validation_split=0.8, epochs=100, \n",
        "                          batch_size=512, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 45568 samples, validate on 182277 samples\n",
            "Epoch 1/100\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "45568/45568 [==============================] - 3s 58us/step - loss: 0.1206 - acc: 0.9928 - val_loss: 0.0065 - val_acc: 0.9983\n",
            "Epoch 2/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0044 - acc: 0.9984 - val_loss: 0.0053 - val_acc: 0.9983\n",
            "Epoch 3/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0037 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 4/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0033 - acc: 0.9984 - val_loss: 0.0048 - val_acc: 0.9983\n",
            "Epoch 5/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0030 - acc: 0.9984 - val_loss: 0.0046 - val_acc: 0.9983\n",
            "Epoch 6/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0027 - acc: 0.9984 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 7/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0027 - acc: 0.9984 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 8/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0025 - acc: 0.9984 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 9/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0024 - acc: 0.9984 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 10/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0023 - acc: 0.9984 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 11/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0023 - acc: 0.9984 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 12/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0023 - acc: 0.9984 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 13/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0022 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 14/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0023 - acc: 0.9984 - val_loss: 0.0051 - val_acc: 0.9983\n",
            "Epoch 15/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0022 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 16/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0021 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 17/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0022 - acc: 0.9984 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 18/100\n",
            "45568/45568 [==============================] - 2s 36us/step - loss: 0.0021 - acc: 0.9984 - val_loss: 0.0051 - val_acc: 0.9983\n",
            "Epoch 19/100\n",
            "45568/45568 [==============================] - 2s 36us/step - loss: 0.0022 - acc: 0.9984 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 20/100\n",
            "45568/45568 [==============================] - 2s 41us/step - loss: 0.0021 - acc: 0.9984 - val_loss: 0.0053 - val_acc: 0.9983\n",
            "Epoch 21/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0021 - acc: 0.9984 - val_loss: 0.0053 - val_acc: 0.9983\n",
            "Epoch 22/100\n",
            "45568/45568 [==============================] - 2s 41us/step - loss: 0.0020 - acc: 0.9984 - val_loss: 0.0054 - val_acc: 0.9983\n",
            "Epoch 23/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0019 - acc: 0.9988 - val_loss: 0.0054 - val_acc: 0.9990\n",
            "Epoch 24/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0021 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9991\n",
            "Epoch 25/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0019 - acc: 0.9993 - val_loss: 0.0054 - val_acc: 0.9992\n",
            "Epoch 26/100\n",
            "45568/45568 [==============================] - 2s 36us/step - loss: 0.0019 - acc: 0.9994 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 27/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9992\n",
            "Epoch 28/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9992\n",
            "Epoch 29/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 30/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 31/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 32/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0019 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 33/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 34/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0018 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9994\n",
            "Epoch 35/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9992\n",
            "Epoch 36/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9994\n",
            "Epoch 37/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 38/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 39/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 40/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 41/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0015 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 42/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9994\n",
            "Epoch 43/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9994\n",
            "Epoch 44/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 45/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0016 - acc: 0.9995 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 46/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 47/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 48/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 49/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 50/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 51/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 52/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9994\n",
            "Epoch 53/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0017 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 54/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 55/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 56/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9994\n",
            "Epoch 57/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 58/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 59/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 60/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 61/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 62/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 63/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 64/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9994\n",
            "Epoch 65/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9994\n",
            "Epoch 66/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9994\n",
            "Epoch 67/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 9.0915e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 68/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 69/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 70/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 9.6221e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 71/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 72/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 9.7128e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 73/100\n",
            "45568/45568 [==============================] - 2s 36us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 74/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 75/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 9.9603e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 76/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 77/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 8.8265e-04 - acc: 0.9998 - val_loss: 0.0061 - val_acc: 0.9993\n",
            "Epoch 78/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9994\n",
            "Epoch 79/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 9.6808e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9994\n",
            "Epoch 80/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 9.7640e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9994\n",
            "Epoch 81/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 9.7492e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9994\n",
            "Epoch 82/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 8.0364e-04 - acc: 0.9998 - val_loss: 0.0063 - val_acc: 0.9993\n",
            "Epoch 83/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 84/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 85/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 86/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 9.5604e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9994\n",
            "Epoch 87/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9994\n",
            "Epoch 88/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 9.5642e-04 - acc: 0.9998 - val_loss: 0.0063 - val_acc: 0.9993\n",
            "Epoch 89/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0061 - val_acc: 0.9993\n",
            "Epoch 90/100\n",
            "45568/45568 [==============================] - 2s 40us/step - loss: 9.6844e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9994\n",
            "Epoch 91/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9994\n",
            "Epoch 92/100\n",
            "45568/45568 [==============================] - 2s 38us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 93/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 9.1979e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 94/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9994\n",
            "Epoch 95/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 8.6049e-04 - acc: 0.9997 - val_loss: 0.0061 - val_acc: 0.9993\n",
            "Epoch 96/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0012 - acc: 0.9996 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 97/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 0.0011 - acc: 0.9996 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 98/100\n",
            "45568/45568 [==============================] - 2s 37us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9994\n",
            "Epoch 99/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 8.6921e-04 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 100/100\n",
            "45568/45568 [==============================] - 2s 39us/step - loss: 8.9079e-04 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 0.9993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1gEac2Abvq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "80868a21-5aca-4d61-a6c3-46cbf098fce0"
      },
      "source": [
        "# Show graphs of training history for accuracy and loss\n",
        "show_train_history(train_history,'acc','val_acc')\n",
        "show_train_history(train_history,'loss','val_loss')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIlKVAkJERKpSQIiISFX/B3sqpiUGXqYmAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrsF8MWCBjtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "b20b159e-01f1-49be-aa7e-4b145712d918"
      },
      "source": [
        "# Get model accuracy \n",
        "scores = model.evaluate(test_features, test_labels)\n",
        "print('\\n')\n",
        "print('accuracy=',scores[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56962/56962 [==============================] - 1s 21us/step\n",
            "\n",
            "\n",
            "accuracy= 0.9990695551420246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJVm4vzwBzK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predictions from model\n",
        "output = model.predict_classes(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKnImmuzCN4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "39ceed07-5bfd-48a9-9318-cb392f7749af"
      },
      "source": [
        "# Show confusion matrix\n",
        "y_actu = pd.Series(test_labels, name='Actual')\n",
        "y_pred = pd.Series(np.ndarray.flatten(output), name='Predicted')\n",
        "df_confusion = pd.crosstab(y_actu, y_pred)\n",
        "print(df_confusion)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted      0   1\n",
            "Actual              \n",
            "0.0        56837  12\n",
            "1.0           41  72\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CTFQ17_CeN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}