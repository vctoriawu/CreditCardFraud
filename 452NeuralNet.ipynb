{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "452NeuralNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpftVxps2kTi",
        "colab_type": "code",
        "outputId": "32168ef7-b136-4d02-88be-f81922c7af7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "import matplotlib.pyplot as plt \n",
        "import io\n",
        "\t\n",
        "from sklearn.utils import resample\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7d9y_tX3-nl",
        "colab_type": "code",
        "outputId": "70260689-e44c-4186-fc24-8667c87cd338",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "# Upload the data file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5c575532-6dec-4005-a62d-3c762cdd77a5\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-5c575532-6dec-4005-a62d-3c762cdd77a5\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving creditcard.csv to creditcard.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0aml3VQ4aig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Store the input data in a dataframe\n",
        "df2 = pd.read_csv(io.BytesIO(uploaded['creditcard.csv']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjN34PkU46AF",
        "colab_type": "code",
        "outputId": "b5eef1a3-095e-4fc6-c00d-b87f0b917bdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Show the first few inputs\n",
        "df2.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG-Et8wf9O8a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to graph training history\n",
        "def show_train_history(train_history,train,validation):\n",
        "    plt.plot(train_history.history[train])\n",
        "    plt.plot(train_history.history[validation])\n",
        "    plt.title('Train History')\n",
        "    plt.ylabel(train)\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['train', 'validation'], loc='best')\n",
        "    plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0IMrGXC9T1O",
        "colab_type": "code",
        "outputId": "91669306-4b8a-45d4-8df7-88089523311e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# shuffle the dataframe so that the inputs are in a random order\n",
        "df = df2.sample(frac=1).reset_index(drop=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>86937.0</td>\n",
              "      <td>-1.283739</td>\n",
              "      <td>2.065273</td>\n",
              "      <td>-1.375477</td>\n",
              "      <td>-1.541884</td>\n",
              "      <td>1.078116</td>\n",
              "      <td>-1.237080</td>\n",
              "      <td>1.634169</td>\n",
              "      <td>-0.294756</td>\n",
              "      <td>0.376591</td>\n",
              "      <td>1.411456</td>\n",
              "      <td>0.755699</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>0.058770</td>\n",
              "      <td>0.380774</td>\n",
              "      <td>-0.757728</td>\n",
              "      <td>-0.603150</td>\n",
              "      <td>-0.815837</td>\n",
              "      <td>-0.013140</td>\n",
              "      <td>0.053396</td>\n",
              "      <td>0.640266</td>\n",
              "      <td>0.078921</td>\n",
              "      <td>0.966021</td>\n",
              "      <td>-0.267667</td>\n",
              "      <td>-0.352384</td>\n",
              "      <td>-0.070779</td>\n",
              "      <td>0.060995</td>\n",
              "      <td>0.470108</td>\n",
              "      <td>0.046423</td>\n",
              "      <td>3.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>158251.0</td>\n",
              "      <td>0.033595</td>\n",
              "      <td>0.771641</td>\n",
              "      <td>0.103641</td>\n",
              "      <td>-0.808490</td>\n",
              "      <td>0.651276</td>\n",
              "      <td>-0.532775</td>\n",
              "      <td>0.880845</td>\n",
              "      <td>-0.007791</td>\n",
              "      <td>-0.210856</td>\n",
              "      <td>-0.231472</td>\n",
              "      <td>0.276824</td>\n",
              "      <td>0.451951</td>\n",
              "      <td>-0.397834</td>\n",
              "      <td>0.361386</td>\n",
              "      <td>-1.024291</td>\n",
              "      <td>0.261588</td>\n",
              "      <td>-0.809362</td>\n",
              "      <td>-0.047136</td>\n",
              "      <td>0.387252</td>\n",
              "      <td>-0.034809</td>\n",
              "      <td>-0.243913</td>\n",
              "      <td>-0.579826</td>\n",
              "      <td>0.007315</td>\n",
              "      <td>-0.510950</td>\n",
              "      <td>-0.468936</td>\n",
              "      <td>0.151648</td>\n",
              "      <td>0.239499</td>\n",
              "      <td>0.081615</td>\n",
              "      <td>5.16</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>129457.0</td>\n",
              "      <td>2.036388</td>\n",
              "      <td>-0.007515</td>\n",
              "      <td>-1.327342</td>\n",
              "      <td>0.334612</td>\n",
              "      <td>0.102665</td>\n",
              "      <td>-1.057305</td>\n",
              "      <td>0.224823</td>\n",
              "      <td>-0.326780</td>\n",
              "      <td>0.510703</td>\n",
              "      <td>-0.013637</td>\n",
              "      <td>-0.292398</td>\n",
              "      <td>0.557223</td>\n",
              "      <td>0.330463</td>\n",
              "      <td>0.440050</td>\n",
              "      <td>0.773418</td>\n",
              "      <td>-0.364487</td>\n",
              "      <td>-0.359470</td>\n",
              "      <td>-0.269621</td>\n",
              "      <td>-0.429691</td>\n",
              "      <td>-0.198024</td>\n",
              "      <td>0.276474</td>\n",
              "      <td>0.929102</td>\n",
              "      <td>0.076061</td>\n",
              "      <td>1.131801</td>\n",
              "      <td>0.232431</td>\n",
              "      <td>-0.163527</td>\n",
              "      <td>-0.020321</td>\n",
              "      <td>-0.046605</td>\n",
              "      <td>8.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14474.0</td>\n",
              "      <td>1.256478</td>\n",
              "      <td>-0.090816</td>\n",
              "      <td>0.309819</td>\n",
              "      <td>-0.163729</td>\n",
              "      <td>0.125398</td>\n",
              "      <td>0.746019</td>\n",
              "      <td>-0.604981</td>\n",
              "      <td>0.134975</td>\n",
              "      <td>1.475953</td>\n",
              "      <td>-0.410868</td>\n",
              "      <td>1.447824</td>\n",
              "      <td>-1.723501</td>\n",
              "      <td>2.521045</td>\n",
              "      <td>1.499643</td>\n",
              "      <td>0.164728</td>\n",
              "      <td>0.759250</td>\n",
              "      <td>-0.206102</td>\n",
              "      <td>0.571585</td>\n",
              "      <td>0.036018</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>-0.069627</td>\n",
              "      <td>0.095122</td>\n",
              "      <td>-0.173814</td>\n",
              "      <td>-1.308666</td>\n",
              "      <td>0.305465</td>\n",
              "      <td>1.125860</td>\n",
              "      <td>-0.074595</td>\n",
              "      <td>-0.020295</td>\n",
              "      <td>15.95</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166729.0</td>\n",
              "      <td>-0.205879</td>\n",
              "      <td>1.196233</td>\n",
              "      <td>-0.979493</td>\n",
              "      <td>-0.071517</td>\n",
              "      <td>0.520330</td>\n",
              "      <td>-1.393490</td>\n",
              "      <td>0.656765</td>\n",
              "      <td>0.051039</td>\n",
              "      <td>-0.226087</td>\n",
              "      <td>-1.113709</td>\n",
              "      <td>-0.706116</td>\n",
              "      <td>0.026867</td>\n",
              "      <td>0.419952</td>\n",
              "      <td>-0.722382</td>\n",
              "      <td>0.638277</td>\n",
              "      <td>0.220689</td>\n",
              "      <td>0.596904</td>\n",
              "      <td>0.776139</td>\n",
              "      <td>-0.137404</td>\n",
              "      <td>-0.243677</td>\n",
              "      <td>0.339017</td>\n",
              "      <td>1.004393</td>\n",
              "      <td>-0.032166</td>\n",
              "      <td>-0.176571</td>\n",
              "      <td>-0.289230</td>\n",
              "      <td>-0.154496</td>\n",
              "      <td>-0.111707</td>\n",
              "      <td>0.020902</td>\n",
              "      <td>9.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   86937.0 -1.283739  2.065273 -1.375477  ...  0.470108  0.046423    3.69      0\n",
              "1  158251.0  0.033595  0.771641  0.103641  ...  0.239499  0.081615    5.16      0\n",
              "2  129457.0  2.036388 -0.007515 -1.327342  ... -0.020321 -0.046605    8.99      0\n",
              "3   14474.0  1.256478 -0.090816  0.309819  ... -0.074595 -0.020295   15.95      0\n",
              "4  166729.0 -0.205879  1.196233 -0.979493  ... -0.111707  0.020902    9.67      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDgDvoYHGncH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Scale the time and amount columns, since the rest of the features are scaled\n",
        "robust_scaler = RobustScaler()\n",
        "\n",
        "df['scaled_amount'] = robust_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['scaled_time'] = robust_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "df.drop(['Time','Amount'], axis=1, inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGSwOsQCG0si",
        "colab_type": "code",
        "outputId": "bb76fe48-74b6-4cdb-bb53-b9c3f340969f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# Scaled amount and time\n",
        "scaled_amount = df['scaled_amount']\n",
        "scaled_time = df['scaled_time']\n",
        "\n",
        "# Insert into beginning of df\n",
        "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
        "df.insert(0, 'scaled_amount', scaled_amount)\n",
        "df.insert(1, 'scaled_time', scaled_time)\n",
        "\n",
        "# Show the result\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>scaled_amount</th>\n",
              "      <th>scaled_time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.255851</td>\n",
              "      <td>0.026375</td>\n",
              "      <td>-1.283739</td>\n",
              "      <td>2.065273</td>\n",
              "      <td>-1.375477</td>\n",
              "      <td>-1.541884</td>\n",
              "      <td>1.078116</td>\n",
              "      <td>-1.237080</td>\n",
              "      <td>1.634169</td>\n",
              "      <td>-0.294756</td>\n",
              "      <td>0.376591</td>\n",
              "      <td>1.411456</td>\n",
              "      <td>0.755699</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>0.058770</td>\n",
              "      <td>0.380774</td>\n",
              "      <td>-0.757728</td>\n",
              "      <td>-0.603150</td>\n",
              "      <td>-0.815837</td>\n",
              "      <td>-0.013140</td>\n",
              "      <td>0.053396</td>\n",
              "      <td>0.640266</td>\n",
              "      <td>0.078921</td>\n",
              "      <td>0.966021</td>\n",
              "      <td>-0.267667</td>\n",
              "      <td>-0.352384</td>\n",
              "      <td>-0.070779</td>\n",
              "      <td>0.060995</td>\n",
              "      <td>0.470108</td>\n",
              "      <td>0.046423</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.235311</td>\n",
              "      <td>0.864190</td>\n",
              "      <td>0.033595</td>\n",
              "      <td>0.771641</td>\n",
              "      <td>0.103641</td>\n",
              "      <td>-0.808490</td>\n",
              "      <td>0.651276</td>\n",
              "      <td>-0.532775</td>\n",
              "      <td>0.880845</td>\n",
              "      <td>-0.007791</td>\n",
              "      <td>-0.210856</td>\n",
              "      <td>-0.231472</td>\n",
              "      <td>0.276824</td>\n",
              "      <td>0.451951</td>\n",
              "      <td>-0.397834</td>\n",
              "      <td>0.361386</td>\n",
              "      <td>-1.024291</td>\n",
              "      <td>0.261588</td>\n",
              "      <td>-0.809362</td>\n",
              "      <td>-0.047136</td>\n",
              "      <td>0.387252</td>\n",
              "      <td>-0.034809</td>\n",
              "      <td>-0.243913</td>\n",
              "      <td>-0.579826</td>\n",
              "      <td>0.007315</td>\n",
              "      <td>-0.510950</td>\n",
              "      <td>-0.468936</td>\n",
              "      <td>0.151648</td>\n",
              "      <td>0.239499</td>\n",
              "      <td>0.081615</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.181793</td>\n",
              "      <td>0.525911</td>\n",
              "      <td>2.036388</td>\n",
              "      <td>-0.007515</td>\n",
              "      <td>-1.327342</td>\n",
              "      <td>0.334612</td>\n",
              "      <td>0.102665</td>\n",
              "      <td>-1.057305</td>\n",
              "      <td>0.224823</td>\n",
              "      <td>-0.326780</td>\n",
              "      <td>0.510703</td>\n",
              "      <td>-0.013637</td>\n",
              "      <td>-0.292398</td>\n",
              "      <td>0.557223</td>\n",
              "      <td>0.330463</td>\n",
              "      <td>0.440050</td>\n",
              "      <td>0.773418</td>\n",
              "      <td>-0.364487</td>\n",
              "      <td>-0.359470</td>\n",
              "      <td>-0.269621</td>\n",
              "      <td>-0.429691</td>\n",
              "      <td>-0.198024</td>\n",
              "      <td>0.276474</td>\n",
              "      <td>0.929102</td>\n",
              "      <td>0.076061</td>\n",
              "      <td>1.131801</td>\n",
              "      <td>0.232431</td>\n",
              "      <td>-0.163527</td>\n",
              "      <td>-0.020321</td>\n",
              "      <td>-0.046605</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.084539</td>\n",
              "      <td>-0.824939</td>\n",
              "      <td>1.256478</td>\n",
              "      <td>-0.090816</td>\n",
              "      <td>0.309819</td>\n",
              "      <td>-0.163729</td>\n",
              "      <td>0.125398</td>\n",
              "      <td>0.746019</td>\n",
              "      <td>-0.604981</td>\n",
              "      <td>0.134975</td>\n",
              "      <td>1.475953</td>\n",
              "      <td>-0.410868</td>\n",
              "      <td>1.447824</td>\n",
              "      <td>-1.723501</td>\n",
              "      <td>2.521045</td>\n",
              "      <td>1.499643</td>\n",
              "      <td>0.164728</td>\n",
              "      <td>0.759250</td>\n",
              "      <td>-0.206102</td>\n",
              "      <td>0.571585</td>\n",
              "      <td>0.036018</td>\n",
              "      <td>-0.019607</td>\n",
              "      <td>-0.069627</td>\n",
              "      <td>0.095122</td>\n",
              "      <td>-0.173814</td>\n",
              "      <td>-1.308666</td>\n",
              "      <td>0.305465</td>\n",
              "      <td>1.125860</td>\n",
              "      <td>-0.074595</td>\n",
              "      <td>-0.020295</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.172291</td>\n",
              "      <td>0.963792</td>\n",
              "      <td>-0.205879</td>\n",
              "      <td>1.196233</td>\n",
              "      <td>-0.979493</td>\n",
              "      <td>-0.071517</td>\n",
              "      <td>0.520330</td>\n",
              "      <td>-1.393490</td>\n",
              "      <td>0.656765</td>\n",
              "      <td>0.051039</td>\n",
              "      <td>-0.226087</td>\n",
              "      <td>-1.113709</td>\n",
              "      <td>-0.706116</td>\n",
              "      <td>0.026867</td>\n",
              "      <td>0.419952</td>\n",
              "      <td>-0.722382</td>\n",
              "      <td>0.638277</td>\n",
              "      <td>0.220689</td>\n",
              "      <td>0.596904</td>\n",
              "      <td>0.776139</td>\n",
              "      <td>-0.137404</td>\n",
              "      <td>-0.243677</td>\n",
              "      <td>0.339017</td>\n",
              "      <td>1.004393</td>\n",
              "      <td>-0.032166</td>\n",
              "      <td>-0.176571</td>\n",
              "      <td>-0.289230</td>\n",
              "      <td>-0.154496</td>\n",
              "      <td>-0.111707</td>\n",
              "      <td>0.020902</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   scaled_amount  scaled_time        V1  ...       V27       V28  Class\n",
              "0      -0.255851     0.026375 -1.283739  ...  0.470108  0.046423      0\n",
              "1      -0.235311     0.864190  0.033595  ...  0.239499  0.081615      0\n",
              "2      -0.181793     0.525911  2.036388  ... -0.020321 -0.046605      0\n",
              "3      -0.084539    -0.824939  1.256478  ... -0.074595 -0.020295      0\n",
              "4      -0.172291     0.963792 -0.205879  ... -0.111707  0.020902      0\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-18ULZbKzL9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split the data into training (80%) and testing (20%)\n",
        "train, test = train_test_split(df, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VriS6xtJa8Q",
        "colab_type": "code",
        "outputId": "58c31495-16c3-4bf8-b089-e15dc6252608",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Upsample fraud data\n",
        "'''df_genuine = train[train.Class==0]\n",
        "df_fraud = train[train.Class==1]\n",
        "\n",
        "df_fraud_upsampled = resample(df_fraud, \n",
        "                                 replace=True,     \n",
        "                                 n_samples=40000,    \n",
        "                                 random_state=123) \n",
        "\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_genuine, df_fraud_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled.Class.value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    227459\n",
              "1     40000\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVvj1GRw-0dv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split data into features and labels\n",
        "train_features = np.array(train.values[:,0:30])\n",
        "train_labels = np.array(train.values[:,-1])\n",
        "test_features = np.array(test.values[:,0:30])\n",
        "test_labels = np.array(test.values[:,-1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0v2zN9TMa0T",
        "colab_type": "code",
        "outputId": "d4b8e328-e34f-4c82-ef0e-756276684252",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(train_features.shape)\n",
        "print(test_features.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(227845, 30)\n",
            "(56962, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xywPxz4d_z57",
        "colab_type": "code",
        "outputId": "078a02b1-7ed1-40fd-a9c3-d64fe1a098e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# Neural network model - may play around with number of layers and nodes a bit more\n",
        "model = Sequential()\n",
        "model.add(Dense(units=100, \n",
        "                input_dim=30, \n",
        "                kernel_initializer='uniform', \n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=100,  \n",
        "                kernel_initializer='uniform', \n",
        "                activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(units=1,\n",
        "                kernel_initializer='uniform',\n",
        "                activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_13 (Dense)             (None, 100)               3100      \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 13,301\n",
            "Trainable params: 13,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x7FkA_lAPzj",
        "colab_type": "code",
        "outputId": "454db332-7796-4784-c038-5c8ee3840c0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "train_history = model.fit(x=train_features, y=train_labels,\n",
        "                          validation_split=0.8, epochs=100, \n",
        "                          batch_size=512, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 45568 samples, validate on 182277 samples\n",
            "Epoch 1/100\n",
            "45568/45568 [==============================] - 2s 36us/step - loss: 0.2327 - acc: 0.9835 - val_loss: 0.0080 - val_acc: 0.9983\n",
            "Epoch 2/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0063 - acc: 0.9982 - val_loss: 0.0053 - val_acc: 0.9983\n",
            "Epoch 3/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0042 - acc: 0.9982 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 4/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0037 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 5/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0031 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 6/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0029 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 7/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0027 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 8/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0031 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 9/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0027 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 10/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0026 - acc: 0.9982 - val_loss: 0.0047 - val_acc: 0.9983\n",
            "Epoch 11/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0026 - acc: 0.9982 - val_loss: 0.0048 - val_acc: 0.9983\n",
            "Epoch 12/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0025 - acc: 0.9982 - val_loss: 0.0048 - val_acc: 0.9983\n",
            "Epoch 13/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0025 - acc: 0.9982 - val_loss: 0.0048 - val_acc: 0.9983\n",
            "Epoch 14/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0024 - acc: 0.9982 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 15/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0024 - acc: 0.9982 - val_loss: 0.0048 - val_acc: 0.9983\n",
            "Epoch 16/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0023 - acc: 0.9982 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 17/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0024 - acc: 0.9982 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 18/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0022 - acc: 0.9982 - val_loss: 0.0049 - val_acc: 0.9983\n",
            "Epoch 19/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0022 - acc: 0.9982 - val_loss: 0.0050 - val_acc: 0.9983\n",
            "Epoch 20/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0021 - acc: 0.9982 - val_loss: 0.0051 - val_acc: 0.9983\n",
            "Epoch 21/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0021 - acc: 0.9982 - val_loss: 0.0051 - val_acc: 0.9983\n",
            "Epoch 22/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0021 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 23/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0020 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 24/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0019 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 25/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0020 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 26/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0020 - acc: 0.9982 - val_loss: 0.0052 - val_acc: 0.9983\n",
            "Epoch 27/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0020 - acc: 0.9982 - val_loss: 0.0053 - val_acc: 0.9983\n",
            "Epoch 28/100\n",
            "45568/45568 [==============================] - 1s 26us/step - loss: 0.0018 - acc: 0.9982 - val_loss: 0.0054 - val_acc: 0.9983\n",
            "Epoch 29/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0018 - acc: 0.9982 - val_loss: 0.0054 - val_acc: 0.9983\n",
            "Epoch 30/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0018 - acc: 0.9982 - val_loss: 0.0055 - val_acc: 0.9983\n",
            "Epoch 31/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0017 - acc: 0.9982 - val_loss: 0.0056 - val_acc: 0.9983\n",
            "Epoch 32/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0019 - acc: 0.9992 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 33/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.0054 - val_acc: 0.9992\n",
            "Epoch 34/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 35/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 36/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0017 - acc: 0.9995 - val_loss: 0.0057 - val_acc: 0.9992\n",
            "Epoch 37/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0018 - acc: 0.9995 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 38/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9992\n",
            "Epoch 39/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 40/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 41/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 42/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 43/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0013 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 44/100\n",
            "45568/45568 [==============================] - 1s 22us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 45/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 46/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 47/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0015 - acc: 0.9996 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 48/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 49/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0014 - acc: 0.9996 - val_loss: 0.0053 - val_acc: 0.9993\n",
            "Epoch 50/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 51/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0054 - val_acc: 0.9993\n",
            "Epoch 52/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 53/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 54/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 55/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 56/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 57/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0055 - val_acc: 0.9993\n",
            "Epoch 58/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 59/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 60/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9998 - val_loss: 0.0056 - val_acc: 0.9993\n",
            "Epoch 61/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 62/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 63/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0012 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 64/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 65/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 66/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0057 - val_acc: 0.9993\n",
            "Epoch 67/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 68/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0011 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 69/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.7135e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 70/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.4291e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 71/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.8910e-04 - acc: 0.9997 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 72/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.2221e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 73/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.1647e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 74/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.7560e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 75/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 7.3741e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 76/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.2978e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 77/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.4265e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 78/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 8.8372e-04 - acc: 0.9998 - val_loss: 0.0058 - val_acc: 0.9993\n",
            "Epoch 79/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.0932e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 80/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.7093e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 81/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.3535e-04 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 82/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9994\n",
            "Epoch 83/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.8081e-04 - acc: 0.9997 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 84/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.6251e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 85/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 86/100\n",
            "45568/45568 [==============================] - 1s 24us/step - loss: 9.1396e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 87/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.2048e-04 - acc: 0.9998 - val_loss: 0.0059 - val_acc: 0.9993\n",
            "Epoch 88/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.2853e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 89/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 90/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.6988e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 91/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 7.2972e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 92/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.2164e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 93/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 9.1757e-04 - acc: 0.9998 - val_loss: 0.0060 - val_acc: 0.9993\n",
            "Epoch 94/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.0436e-04 - acc: 0.9998 - val_loss: 0.0061 - val_acc: 0.9993\n",
            "Epoch 95/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.9293e-04 - acc: 0.9997 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 96/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.4879e-04 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 97/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.5928e-04 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 0.9993\n",
            "Epoch 98/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 8.5414e-04 - acc: 0.9998 - val_loss: 0.0063 - val_acc: 0.9993\n",
            "Epoch 99/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 7.1995e-04 - acc: 0.9998 - val_loss: 0.0063 - val_acc: 0.9993\n",
            "Epoch 100/100\n",
            "45568/45568 [==============================] - 1s 23us/step - loss: 7.7274e-04 - acc: 0.9998 - val_loss: 0.0062 - val_acc: 0.9993\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6S1gEac2Abvq",
        "colab_type": "code",
        "outputId": "c1b9d345-4951-49b5-aeaf-78e304956ffb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        }
      },
      "source": [
        "# Show graphs of training history for accuracy and loss\n",
        "show_train_history(train_history,'acc','val_acc')\n",
        "show_train_history(train_history,'loss','val_loss')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMxsWBw4zMxsWP5/qSrl3abt/ZoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrsF8MWCBjtj",
        "colab_type": "code",
        "outputId": "321671ea-bd08-46c6-e8b4-1da79ddd53d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Get model accuracy \n",
        "scores = model.evaluate(test_features, test_labels)\n",
        "print('\\n')\n",
        "print('accuracy=',scores[1])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "56962/56962 [==============================] - 1s 23us/step\n",
            "\n",
            "\n",
            "accuracy= 0.999385555282469\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJVm4vzwBzK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get predictions from model\n",
        "output = model.predict_classes(test_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKnImmuzCN4L",
        "colab_type": "code",
        "outputId": "d2c9e1d3-4926-4ed7-a755-ac4c14f3bdf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# Show confusion matrix\n",
        "y_actu = pd.Series(test_labels, name='Actual')\n",
        "y_pred = pd.Series(np.ndarray.flatten(output), name='Predicted')\n",
        "df_confusion = pd.crosstab(y_actu, y_pred)\n",
        "print(df_confusion)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicted      0   1\n",
            "Actual              \n",
            "0.0        56847  10\n",
            "1.0           25  80\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CTFQ17_CeN_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}